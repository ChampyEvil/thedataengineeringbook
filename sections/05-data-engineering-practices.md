# Data Engineering Practices

## ออกแบบให้งานสามารถทำซ้ำ (Reproducible) ได้

ความท้าทายอย่างหนึ่งในการสร้าง Data Pipelines คือการออกแบบให้งานแต่ละงานนั้นสามารถทำซ้ำ หรือ Reproducible ได้ ซึ่งนั่นก็หมายความว่าเราสามารถที่จะรัน Pipeline ของเราใหม่ไม่ว่าจะกี่ครั้ง หรือไม่ว่าจะเวลาใดก็ตาม เราสามารถที่จะคาดหวังผลลัพธ์สุดท้ายได้เสมอ

### เขียนฟังก์ชั่นการทำงานให้มีสมบัติ Idempotent

Idempotent เป็นสมบัติอย่างหนึ่งของฟังก์ชั่นทางคณิตศาสตร์ เราจะได้ผลลัพธ์เป็นค่าเดิมเสมอ ไม่ว่าเราจะดำเนินการกี่ครั้งแล้วก็ตาม ตรงนี้เป็นส่วนสำคัญในการสร้าง Data Pipelines เลยทีเดียว

### ผลลัพธ์ของงานควรจะเป็น Deterministic

เราสามารถกล่าวได้ว่า งานของเราสามารถทำซ้ำได้ ถ้างานเหล่านั้นเป็น Deterministic แปลว่างานนั้นๆ จะคืนค่าผลลัพธ์เดิมเสมอ ถ้าเราใส่อินพุตค่าเดิม

## ในการพัฒนา Data Pipeline ให้เก็บข้อมูลไว้ที่ Shared Storage เสมอ

ตอนที่เราจัดการข้อมูลต่างๆ ใน Data Pipeline มักจะมีการอ่านและเขียนข้อมูลจากงานต่างๆ ใน Data Pipeline อยู่เป็นประจำ และงานแต่ละงานก็มักจะแชร์ข้อมูลระหว่างกัน การที่เราเก็บไฟล์ไว้ที่ Local File System ก็เป็นวิธีหนึ่งที่สามารถทำได้ ในกรณีที่เราจัดการระบบภายในเครื่อง 1 เครื่อง

ซึ่งในทางปฏิบัติแล้วเรามักจะมีเครื่องอยู่หลายเครื่อง ระบบเป็นแบบ Distributed และมีตัว Worker หลายตัวมาทำงานร่วมกันอยู่ ทำให้ถ้าเราสั่งให้งานๆ หนึ่งเขียนไฟล์ลง Local File System ไว้ ก็จะมีความเป็นไปได้สูงว่างานอื่นๆ ที่รันอยู่คนละเครื่องจะไม่สามารถเข้าถึงไฟล์นั้นได้

วิธีที่ง่ายที่สุดในการแก้ปัญหานี้คือให้เราใช้ Shared Storage แทน ซึ่ง Worker แต่ละตัว งานแต่ละงานจะสามารถเข้าถึงไฟล์ที่ต่างคนต่างเขียนลงมาได้